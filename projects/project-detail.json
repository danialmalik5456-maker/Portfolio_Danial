[
  {
    "id": 1,
    "title": "Segmentation and Counting of Capillaries in Biomedical Images",
    "category": "Medical Image Computing / Computer Vision",
    "technologies": "Python, OpenCV, scikit-image, NumPy, Matplotlib, Pandas, SciPy, Jupyter, ImageIO, Morphological Operations, CLAHE, Frangi Filter, Sato Filter, Meijering Filter, Otsuâ€™s Thresholding, Connected Components Analysis, CSV Data Logging",
    "thumbnail": "../img/projects/id1/thumbnail.png",
    "banner": "../img/projects/id1/banner.jpg",
    "description": [
      {
        "type": "paragraph",
        "text": "Developed a robust, semi-automated image processing pipeline to enhance, segment, and quantify microvascular structures (capillaries) from native biomedical tongue images, critical for diagnosing conditions like diabetes and hypertension."
      },
      {
        "type": "bullet",
        "text": "Applied adaptive preprocessing techniques including CLAHE (Contrast Limited Adaptive Histogram Equalization) and Median Filtering, with parameters meticulously tuned to maintain accuracy across four distinct clinical datasets (N1, N2, S2, S3)."
      },
      {
        "type": "bullet",
        "text": "Implemented a combined vesselness-based enhancement map by averaging the outputs of the Frangi, Sato, and Meijering filters to effectively highlight the tubular capillary structures."
      },
      {
        "type": "bullet",
        "text": "Used Otsuâ€™s Thresholding for automatic binarization, followed by rigorous morphological post-processing (closing, small object/hole removal) to refine the final vessel masks and ensure segment continuity."
      },
      {
        "type": "bullet",
        "text": "Integrated a quantitative capillary counting algorithm using Connected Components Analysis on a standardized and rotated Region of Interest (ROI) for reproducible analysis."
      },
      {
        "type": "paragraph",
        "text": "The project successfully validated a reliable, reproducible, and adaptable classical image processing solution, providing a solid foundation for quantitative microvascular analysis."
      }
    ],
    "duration": "Feb 2025 â€“ June 2025",
    "role": "Computer Vision Researcher / Developer",
    "outcome": "Developed a reliable and reproducible pipeline for capillary segmentation and quantification, paving the way for integration of deep learning models for medical diagnostics.",
    "github": "https://github.com/malikdanialahmed/Segmentation-and-Counting-of-Capillaries-in-Biomedical-Images/tree/main",
    "gallery": [
      "../img/projects/id1/v1.jpg",
      "../img/projects/id1/v2.jpg",
      "../img/projects/id1/v3.jpg",
      "../img/projects/id1/v4.jpg",
      "../img/projects/id1/v5.jpg",
      "../img/projects/id1/v6.jpg",
      "../img/projects/id1/v7.png"
    ]
  },
  {
    "id": 2,
    "title": "Medical Image Restoration: De-Blurring and De-Noising using Wiener Deconvolution and Bilateral Filtering",
    "category": "Scene Segmentation & Interpretation, Medical Imaging",
    "technologies": "Wiener Deconvolution, Bilateral Filtering, Radon Transform, Fourier Analysis, PSNR, SNR, Python, OpenCV",
    "thumbnail": "../img/projects/id2/thumbnail.jpg",
    "banner": "../img/projects/id2/banner.jpg",
    "description": [
      {
        "type": "paragraph",
        "text": "Developed and implemented a complete image restoration pipeline to enhance the clarity of medical images (specifically motion-blurred and noisy MRI scans) to aid in accurate diagnosis."
      },
      {
        "type": "bullet",
        "text": "Implemented a two-part blur estimation method using the Radon Transform to estimate the blur angle (e.g., 177.19 degrees) and Fourier Analysis to estimate the blur size (e.g., 22 pixels) for the Point Spread Function (PSF)."
      },
      {
        "type": "bullet",
        "text": "Employed Wiener Deconvolution with a regularization parameter K=0.01 for effective motion blur restoration."
      },
      {
        "type": "bullet",
        "text": "Applied Bilateral Filtering for denoising to preserve essential image edges, using heuristic-based suggested parameters (Diameter=7, Sigma Spatial=7.0, Sigma Intensity=20.0)."
      },
      {
        "type": "bullet",
        "text": "Quantified restoration success using quality metrics: improved PSNR from 19.81 dB after deblurring to 28.87 dB after final bilateral filtering."
      },
      {
        "type": "paragraph",
        "text": "The final pipeline demonstrated a significant increase in image quality, validating its effectiveness and practicality for enhancing diagnostically useful images while preserving structural details."
      }
    ],
    "duration": " March - April 2025",
    "role": "Computer Vision Developer",
    "outcome": "Successfully restored a blurred and noisy MRI image, demonstrating significant improvement in clarity. The system achieved a final PSNR of 28.87 dB (an increase of 9.06 dB from the post-deblurring PSNR of 19.81 dB) using only the system's suggested parameters, validating the pipeline's reliable and efficient performance.",
    "github": "https://github.com/malikdanialahmed/De-Blurring-and-De-Noising/tree/main",
    "gallery": [
      "../img/projects/id2/dfs.jpg",
      "../img/projects/id2/Figure 2.jpg",
      "../img/projects/id2/Figure 3.jpg",
      "../img/projects/id2/featured-thumbnail.jpg",
      "../img/projects/id2/banner.jpg",
      "../img/projects/id2/thumbnail.jpg"
    ]
  },
  {
    "id": 3,
    "title": "3D Geometry Reconstruction Using Stereo Vision",
    "category": "Computer Vision",
    "technologies": "Python, OpenCV, AKAZE, StereoSGBM, RANSAC, Fundamental/Essential Matrix, SVD, Basler Pylon API",
    "thumbnail": "../img/projects/id3/bg5.jpg",
    "banner": "../img/projects/id3/banner.png",
    "description": [
      {
        "type": "paragraph",
        "text": "Developed a portable, low-cost computer vision system for real-time 3D geometry reconstruction using a synchronized dual-camera stereo setup. The goal was to generate accurate, dense 3D point clouds of a physical scene."
      },
      {
        "type": "bullet",
        "text": "Implemented a complete stereo vision pipeline: Camera Calibration (Zhang's method) â†’ Stereo Rectification â†’ Sparse & Dense 3D Reconstruction."
      },
      {
        "type": "bullet",
        "text": "Utilized the AKAZE feature detector and RANSAC for robust outlier removal to estimate the Fundamental and Essential Matrices, ensuring geometric accuracy."
      },
      {
        "type": "bullet",
        "text": "Performed Sparse 3D Reconstruction by decomposing the Essential Matrix using SVD to find the relative rotation and translation, followed by triangulation of matched features."
      },
      {
        "type": "bullet",
        "text": "Achieved Dense 3D Reconstruction by generating a disparity map using the high-performance StereoSGBM algorithm, which was then refined with a Weighted Least Squares (WLS) Filter."
      },
      {
        "type": "bullet",
        "text": "Developed a custom GUI using an specified Python library Tkinter to provide real-time visualization of the stereo images, disparity map, and the final 3D point cloud."
      },
      {
        "type": "paragraph",
        "text": "The project successfully validated the geometric constraints and produced high-fidelity 3D point clouds, serving as a functional foundation for applications in robotics and metrology."
      }
    ],
    "duration": "Feb 2025 â€“ May 2025",
    "role": "Software Developer",
    "outcome": "Developed a robust and verifiable system capable of accurate 3D scene mapping from stereo vision. Successfully validated the entire pipeline, proving the ability to compute relative pose and generate both sparse feature clouds and dense, filtered 3D reconstructions.",
    "github": "https://github.com/hassaanahmed04/Computer-Vision",
    "gallery": [
      "../img/projects/id3/0.png",
      "../img/projects/id3/1.jpeg",
      "../img/projects/id3/2.png",
      "../img/projects/id3/3.jpg",
      "../img/projects/id3/4.png",
      "../img/projects/id3/5.jpg",
      "../img/projects/id3/6.jpg",
      "../img/projects/id3/7.jpg",
      "../img/projects/id3/8.png",
      "../img/projects/id3/9.jpg",
      "../img/projects/id3/10.jpeg",
      "../img/projects/id3/g1.jpg",
      "../img/projects/id3/g2.jpg",
      "../img/projects/id3/g3.jpg",
      "../img/projects/id3/g4.jpg",
      "../img/projects/id3/g5.jpg"
      
    ]
  },
  {
    "id": 4,
    "title": "ANPR Web Application for Stolen Vehicles",
    "category": "Computer Vision, Web Application, Bachelor Final Year Project",
    "technologies": "Python, Django, Optical Character Recognition (OCR), Image Processing, Neural Network Techniques, ORM",
    "thumbnail": "../img/projects/id4/thumbnail.webp",
    "banner": "../img/projects/id4/banner.jpg",
    "description": [
      {
        "type": "paragraph",
        "text": "Developed an Automatic Number Plate Recognition (ANPR) web application as a part of Bachelor Final Year Project to facilitate law enforcement agencies in analyzing and finding stolen vehicles. The system is built on Neural Network techniques for robust recognition."
      },
      {
        "type": "bullet",
        "text": "Implemented the core ANPR pipeline which processes images/video streams through Preprocessing, Plate Localization, Character Segmentation, and Neural Network-based Optical Character Recognition (OCR)."
      },
      {
        "type": "bullet",
        "text": "Designed and deployed a secure web application interface (Admin Panel and User Authentication) to manage vehicle records and control system access."
      },
      {
        "type": "bullet",
        "text": "Features a critical real-time alert system that instantly notifies administrators via message/email when a stolen vehicle is detected passing through ANPR-enabled checkpoints, including location and time reports."
      },
      {
        "type": "bullet",
        "text": "The system includes full vehicle management modules (Add/Search/Delete FIR) and provides sophisticated database management with graphical reporting and PDF export facilities."
      },
      {
        "type": "paragraph",
        "text": "The system automates the traditionally manual process of checking camera footage, significantly reducing the workload for law enforcement and enhancing the efficiency of detecting stolen vehicles."
      }
    ],
    "duration": "April 2022 â€“ February 2023",
    "role": "ANPR/Web Application Development Team Member",
    "outcome": "Successfully delivered a functional, web-based ANPR system with a proven recognition engine, providing law enforcement with easy, real-time access to vehicle records.",
    "github": "ðŸ‘‰ Paste your GitHub repo link here",
    "gallery": [
      "../img/projects/id4/1.jpg",
      "../img/projects/id4/2.JPG",
      "../img/projects/id4/3.JPG",
      "../img/projects/id4/4.JPG",
      "../img/projects/id4/5.JPG",
      "../img/projects/id4/6.JPG",
      "../img/projects/id4/7.JPG"
    ]
  },
  {
    "id": 5,
    "title": "Research Analysis & Presentation: Structure from Motion (SfM) Approaches & Applications",
    "category": "Image processing",
    "technologies": "Structure from Motion (SfM), Multi-View Stereo (MVS), Digital Elevation Models (DEMs), 3D Point Clouds, Computer Vision Principles, Presentation/Defense",
    "thumbnail": "../img/projects/id5/thumbnail.png",
    "banner": "../img/projects/id5/banner.png",
    "description": [
      {
        "type": "paragraph",
        "text": "In-depth research and presentation of the paper 'Structure from Motion (SfM) â€“ Approaches & Applications,' focusing on the analysis, defense, and communication of advanced 3D photogrammetry techniques."
      },
      {
        "type": "bullet",
        "text": "Analyzed and synthesized the core principles of Structure from Motion (SfM), a computer vision method used to reconstruct high-resolution 3D models and point clouds from standard 2D images."
      },
      {
        "type": "bullet",
        "text": "Compared and contrasted SfM with traditional topographic surveying methods (GPS, Laser Scanning), highlighting its advantage in low-cost, high-resolution data acquisition using consumer-grade cameras."
      },
      {
        "type": "bullet",
        "text": "Detailed the workflow of SfM, including automatic camera pose estimation, sparse and dense 3D reconstruction, and the generation of Digital Elevation Models (DEMs)."
      },
      {
        "type": "bullet",
        "text": "Presented a comprehensive poster outlining the methodology, applications, and validation of SfM across various geoscience fields (e.g., geomorphology, mapping)."
      },
      {
        "type": "paragraph",
        "text": "Successfully defended the technical concepts of SfM photogrammetry to an academic committee, demonstrating mastery of the subject matter, critical analysis, and technical communication skills."
      }
    ],
    "duration": "Dec 2024",
    "role": "Research Analyst & Presenter",
    "outcome": "Successfully communicated complex 3D reconstruction concepts, demonstrating strong research, critical analysis, and technical defense skills. Achieved high marks for presenting the utility and methodology of Structure from Motion as a modern, cost-effective alternative to traditional 3D mapping techniques.",
    "github": "N/A (Theoretical/Presentation Project)",
    "gallery": [
      "../img/projects/id5/0.jpg",
      "../img/projects/id5/1.png",
      "../img/projects/id5/2.png",
      "../img/projects/id5/3.png",
      "../img/projects/id5/4.png",
      "../img/projects/id5/5.png",
      "../img/projects/id5/6.png"
    ]
},
{
    "id": 6,
    "title": "Research Analysis & Presentation: Audio Augmentation for Speech Recognition",
    "category": "Speech Recognition (ASR), Deep Learning (DNN), Data Augmentation, Digital Signal Processing",
    "technologies": "Speed Perturbation, VTLP, Time-Delay Neural Networks (TDNN), Mel-frequency Cepstral Coefficients (MFCCs), LVCSR, Python (SoX Audio Tool)",
    "thumbnail": "../img/projects/id6/thumbnail.png",
    "banner": "../img/projects/id6/banner.png",
    "description": [
      {
        "type": "paragraph",
        "text": "In-depth research and academic defense of the INTERSPEECH 2015 paper, 'Audio Augmentation for Speech Recognition', which investigates simple, audio-level techniques to increase training data and improve the robustness of Deep Neural Network (DNN) based speech recognition models. The project focused on critically analyzing the paper's methodology and quantitative results."
      },
      {
        "type": "bullet",
        "text": "The core technique analyzed is Speed Perturbation, which creates three augmented versions of the original audio signal using speed factors of '0.9, 1.0, and 1.1'. This method has a low implementation cost."
      },
      {
        "type": "bullet",
        "text": "Analyzed why Speed Perturbation is superior to existing methods like VTLP and Tempo Perturbation, as it uniquely emulates a combination of both time warping and log Mel spectral envelope perturbation."
      },
      {
        "type": "bullet",
        "text": "The technique was validated on four different Large Vocabulary Continuous Speech Recognition (LVCSR) tasks (Switchboard, TedLIUM, Librispeech, GALE Mandarin) using state-of-the-art Time-Delay Neural Networks (TDNN) as the acoustic model."
      },
      {
        "type": "bullet",
        "text": "The experiments demonstrated a significant outcome: an average relative improvement of 4.3% in Word Error Rate (WER) across the four tasks, including a 6.7% relative improvement on the Switchboard (SWB) benchmark."
      },
      {
        "type": "paragraph",
        "text": "Successfully defended the mechanism, implementation (using the SoX tool), and quantitative results of speed perturbation to an academic committee, demonstrating mastery of ASR data augmentation and robust technical communication skills."
      }
    ],
    "duration": "Dec 2024",
    "role": "Research Analyst & Presenter",
    "outcome": "Demonstrated advanced comprehension of modern ASR modeling challenges (data scarcity, robustness) and effective solutions through data augmentation. Successfully defended the findings and methodology of the research paper, showcasing strong technical communication and analytical skills.",
    "github": "N/A (Theoretical/Presentation Project)",
    "gallery": [
      "../img/projects/id6/0.jpg",
      "../img/projects/id6/1.png",
      "../img/projects/id6/2.png",
      "../img/projects/id6/3.png"
    ]
},
  {
    "id": 7,
    "title": "Expectation-Maximization (EM) Based Brain Tissue Segmentation",
    "category": "Medical Image Processing, Machine Learning, Brain Segmentation, Clustering",
    "technologies": "Expectation-Maximization (EM), Gaussian Mixture Models (GMM), K-Means Clustering, Dice Score, Unimodal/Multimodal Segmentation",
    "thumbnail": "../img/projects/id7/1.png",
    "banner": "../img/projects/id7/banner.png",
    "description": [
        {
            "type": "paragraph",
            "text": "Implementation and comparative analysis of two initialization strategies for the Expectation-Maximization (EM) algorithm used for brain tissue segmentation with Gaussian Mixture Models (GMM). The goal was to accurately segment the brain parenchyma into K=3 tissue classes: Cerebrospinal Fluid (CSF), Gray Matter (GM), and White Matter (WM)."
        },
        {
            "type": "bullet",
            "text": "The core comparison focused on Random Initialization (the baseline) versus K-Means Clustering Initialization for setting the initial means, covariance matrices, and mixing coefficients of the GMM."
        },
        {
            "type": "bullet",
            "text": "The pipeline was designed to handle both Unimodal Segmentation (using T1-weighted MRI only) and Multimodal Segmentation (combining T1 and T2_FLAIR MRI sequences to create a 2D feature vector for classification)."
        },
        {
            "type": "bullet",
            "text": "Preprocessing steps included loading NIfTI data, applying a Median Filter for noise reduction, and generating a Brain Mask to focus the EM algorithm on relevant voxels."
        },
        {
            "type": "bullet",
            "text": "Segmentation accuracy was quantitatively evaluated using the Dice Score against ground truth labels for each tissue class (CSF, GM, WM)."
        },
        {
            "type": "paragraph",
            "text": "The results demonstrated that using K-Means Initialization significantly improves the stability and consistency of the EM algorithm, often leading to better Dice Scores by avoiding suboptimal local minima compared to purely random starts."
        }
    ],
    "duration": "Academic Project",
    "role": "Machine Learning Implementer & Analyst",
    "outcome": "Successfully implemented and benchmarked the EM segmentation pipeline across different initialization and modality settings. Demonstrated advanced technical skills in custom EM implementation, medical image preprocessing (Nibabel, SciPy), and quantitative evaluation of segmentation results, proving the superiority of KMeans initialization for this task.",
    "github": "https://github.com/malikdanialahmed/Brain-Image-Segmentation-using-Expectation-Maximization-EM-",
    "gallery": [
        "../img/projects/id7/labels_em_sub1.jpg",
        "../img/projects/id7/prob_csf_sub1.jpg",
        "../img/projects/id7/prob_gm_sub1.jpg",
        "../img/projects/id7/prob_wm_sub1.jpg",
        "../img/projects/id7/Overlay case 1.png",
        "../img/projects/id7/banner.png",
        "../img/projects/id7/kmeans multi segmentation case 4.png"
    ]
}

]

